<!DOCTYPE html>
<head>
<meta charset=utf-8>
<title>Caso di studio: convertire chardet verso Python 3 - Dive into Python 3</title>
<!--[if IE]><script src=html5.js></script><![endif]-->
<link rel=stylesheet type=text/css href=dip3.css>
<link rel=stylesheet type=text/css href=dip3-it.css>
<style>
body{counter-reset:h1 20}
ins,del{line-height:2.154;text-decoration:none;font-style:normal;display:inline-block;width:100%}
ins{background:#9f9}
del{background:#f87}
</style>
<link rel=stylesheet type=text/css media='only screen and (max-device-width: 480px)' href=mobile.css>
</head>
<form action=http://www.google.com/cse><div><input type=hidden name=cx value=014021643941856155761:l5eihuescdw><input type=hidden name=ie value=UTF-8>&nbsp;<input name=q size=25>&nbsp;<input type=submit name=sa value=Search></div></form>
<p>Voi siete qui: <a href=index.html>Home</a> <span>&#8227;</span> <a href=table-of-contents.html#case-study-porting-chardet-to-python-3>Dive Into Python 3</a> <span>&#8227;</span>
<p id=level>Livello di difficoltà: <span title=pro>&#x2666;&#x2666;&#x2666;&#x2666;&#x2666;</span>
<h1>Caso di studio: convertire <code>chardet</code> verso Python 3</h1>
<blockquote class=q>
<p><span>&#x275D;</span> Parole, non abbiamo altro che parole per andare avanti. <span>&#x275E;</span><br>&mdash; <a href=http://www.imdb.com/title/tt0100519/quotes>Rosencrantz e Guildenstern sono morti</a>
</blockquote>
<p id=toc>&nbsp;
<h2 id=divingin>Immersione!</h2>
<p class=f>Una codifica di caratteri scorretta o sconosciuta è la causa n°1 della presenza di testo inintelleggibile sul web, nella vostra casella di posta, e in verità attraverso ogni sistema computerizzato mai scritto. Nel <a href=stringhe.html>Capitolo 3</a>, ho parlato della storia delle codifiche di carattere e della creazione di Unicode, &#8220;una codifica per governarle tutte.&#8221; Mi piacerebbe non dover mai più vedere un carattere incomprensibile su una pagina web, perché tutti i sistemi d'autore memorizzerebbero informazioni di codifica accurate, tutti i protocolli di trasferimento conoscerebbero Unicode, e ogni sistema che gestisce del testo manterrebbe una fedeltà perfetta nel convertirlo tra diverse codifiche.
<p>Mi piacerebbe anche un pony.
<p>Un pony Unicode.
<p>Uno Unipony, per così dire.
<p>Mi accontenterò del riconoscimento automatico delle codifiche di carattere.

<h2 id=faq.what>Che cos'è il riconoscimento automatico delle codifiche di carattere?</h2>
<p>Significa prendere una sequenza di byte in una codifica di carattere sconosciuta, e cercare di determinare la codifica in modo da poter leggere il testo. &Egrave; come scassinare un codice quando non avete la chiave di decrittazione.

<h3 id=faq.impossible>Ma non è impossibile?</h3>
<p>In generale, sì. Comunque, alcune codifiche sono ottimizzate per lingue specifiche, e le lingue non sono casuali. Alcune sequenze di caratteri compaiono tutte le volte, mentre altre sequenze non hanno senso. Una persona fluente in inglese che apre un giornale e trova &#8220;txzqJv 2!dasd0a QqdKjvz&#8221; riconoscerà istantaneamente che quello non è inglese (sebbene sia composto interamente di lettere inglesi). Analizzando grandi quantità di testo &#8220;tipico&#8221;, un algoritmo per computer può simulare questo tipo di fluenza e fare una ipotesi fondata sulla lingua in cui è scritto un testo.
<p>In altre parole, il riconoscimento di una codifica è in realtà il riconoscimento di una lingua, combinata con la conoscenza di quali lingue tendono ad usare quali codifiche di carattere.

<h3 id=faq.who>Esiste un algoritmo di questo tipo?</h3>
<p>A quanto pare, sì. Tutti browser più diffusi usano il riconoscimento automatico delle codifiche di carattere, perché il web è pieno di pagine che non hanno alcuna informazione sulla loro codifica. <a href=http://lxr.mozilla.org/seamonkey/source/extensions/universalchardet/src/base/>Mozilla Firefox contiene una libreria per il riconoscimento automatico delle codifiche</a> che è open source. <a href=http://chardet.feedparser.org/>Io ho convertito questa libreria in Python 2</a> e ho chiamato il modulo <code>chardet</code>. Questo capitolo vi porterà passo per passo attraverso il processo di conversione del modulo <code>chardet</code> da Python 2 a Python 3.

<h2 id=divingin2>Introduzione al modulo <code>chardet</code></h2>
<p><span class=fixme>[FIXME download link, possibly on chardet.feedparser.org, possibly local]</span>
<p>Prima di cominciare a convertire il codice, potrebbe aiutare se capiste come il codice funziona! Questa è una breve guida per navigare il codice stesso.
<aside>Il riconoscimento di codifica è in realtà il riconoscimento di una lingua travestito.</aside>
<p>Il punto d'entrata principale per l'algoritmo di riconoscimento è <code>universaldetector.py</code>, dove viene definita la classe <code>UniversalDetector</code>. (Potreste pensare che il punto d'entrata principale sia la funzione <code>detect</code> in <code>chardet/__init__.py</code>, ma quella è in realtà solo una funzione di convenienza che crea un oggetto di tipo <code>UniversalDetector</code>, lo invoca, e ne restituisce risultato.)
<p>Ci sono 5 categorie di codifica che <code>UniversalDetector</code> gestisce:
<ol>
<li><code>UTF-n</code> con <abbr title="Byte Order Mark">BOM</abbr>. Questo comprende <code>UTF-8</code>, sia le varianti <abbr title="Big Endian">BE</abbr> che <abbr title="Little Endian">LE</abbr> di <code>UTF-16</code>, e tutte e 4 le varianti di <code>UTF-32</code> con un ordine di byte differente.
<li>Codifiche con escape, che sono interamente compatibili con la codifica <abbr>ASCII</abbr> a 7 bit, dove i caratteri non-<abbr>ASCII</abbr> cominciano con una sequenza di escape. Esempi: <code>ISO-2022-JP</code> (giapponese) e <code>HZ-GB-2312</code> (cinese).
<li>Codifiche multi-byte, dove ogni carattere è rappresentato da un numero variabile di byte. Esempi: <code>Big5</code> (cinese), <code>SHIFT_JIS</code> (giapponese), <code>EUC-KR</code> (coreano), e <code>UTF-8</code> senza <abbr title="Byte Order Mark">BOM</abbr>.
<li>Codifiche a singolo byte, dove ogni carattere è rappresentato da un byte. Esempi: <code>KOI8-R</code> (russo), <code>windows-1255</code> (ebraico), e <code>TIS-620</code> (thai).
<li><code>windows-1252</code>, che viene usato principalmente sotto Microsoft Windows da direttori d'azienda che non distinguerebbero una codifica di carattere da un buco in terra.
</ol>
<h3 id=how.bom><code>UTF-n</code> con <abbr title="Byte Order Mark">BOM</abbr></h3>
<p>Se il testo comincia con un <abbr title="Byte Order Mark">BOM</abbr>, possiamo ragionevolmente presumere che il testo sia codificato in <code>UTF-8</code>, <code>UTF-16</code>, o <code>UTF-32</code>. (Il <abbr title="Byte Order Mark">BOM</abbr> ci dirà esattamente quale; questo è quello a cui serve.) Questo viene gestito inline da <code>UniversalDetector</code>, che restituisce il risultato immediatamente senza ulteriori elaborazioni.
<h3 id=how.esc>Codifiche con escape</h3>
<p>Se il testo contiene una sequenza di escape riconoscibile che potrebbe indicare una codifica con escape, <code>UniversalDetector</code> crea un <code>EscCharSetProber</code> (definito in <code>escprober.py</code>) e gli passa il testo.
<p><code>EscCharSetProber</code> crea una serie di macchine a stati finiti, basate sui modelli di <code>HZ-GB-2312</code>, <code>ISO-2022-CN</code>, <code>ISO-2022-JP</code>, e <code>ISO-2022-KR</code> (definiti in <code>escsm.py</code>). <code>EscCharSetProber</code> passa il testo a ognuna di queste macchine a stati, un byte alla volta. Se una qualsiasi di queste macchine a stati finisce per identificare univocamente la codifica, <code>EscCharSetProber</code> restituisce immediatamente il risultato positivo a <code>UniversalDetector</code>, che lo restituisce al chiamante. Se una qualsiasi delle macchine a stati trova una sequenza illegale, viene scartata e l'elaborazione continua con le altre macchine a stati.
<h3 id=how.mb>Codifiche multi-byte</h3>
<p>Presumendo che non ci sia un <abbr title="Byte Order Mark">BOM</abbr>, <code>UniversalDetector</code> controlla se il testo contiene un carattere <span class=wtf>high-bit</span>. Se è così, crea una serie di &#8220;sonde&#8221; per riconoscere le codifiche multi-byte, a singolo byte e, come ultima risorsa, <code>windows-1252</code>.
<p>La sonda per le codifiche multi-byte, <code>MBCSGroupProber</code> (definita in <code>mbcsgroupprober.py</code>), in realtà si occupa solo di gestire un gruppo di altre sonde, una per ogni codifica multi-byte: <code>Big5</code>, <code>GB2312</code>, <code>EUC-TW</code>, <code>EUC-KR</code>, <code>EUC-JP</code>, <code>SHIFT_JIS</code>, e <code>UTF-8</code>. <code>MBCSGroupProber</code> passa il testo a ognuna di queste specifiche sonde e controlla i risultati. Se una sonda riporta di aver trovato una sequenza illegale di byte, viene scartata da ulteriori elaborazioni (in modo che, per esempio, ogni chiamata successiva a <code>UniversalDetector</code>.<code>feed()</code> salterà quella sonda). Se una sonda riporta di essere ragionevolmente fiduciosa di aver riconosciuto la codifica, <code>MBCSGroupProber</code> riporta questo risultato positivo a <code>UniversalDetector</code>, che riporta a sua volta il risultato al chiamante.
<p>La maggior parte delle sonde per le codifiche multi-byte eredita da <code>MultiByteCharSetProber</code> (definita in <code>mbcharsetprober.py</code>), e semplicemente aggancia la macchina a stati e l'analizzatore di distribuzione appropriati lasciando che sia <code>MultiByteCharSetProber</code> a fare il resto del lavoro. <code>MultiByteCharSetProber</code> fa scorrere il testo attraverso la macchina a stati della specifica codifica, un byte alla volta, per cercare sequenze di byte che indicherebbero un risultato conclusivo positivo o negativo. Allo stesso tempo, <code>MultiByteCharSetProber</code> passa il testo a un analizzatore di distribuzione specifico per quella codifica.
<p>Gli analizzatori di distribuzione (ognuno definito in <code>chardistribution.py</code>) usano modelli specifici per ogni lingua di quali caratteri vengono usati più frequentemente. Una volta che <code>MultiByteCharSetProber</code> ha passato abbastanza testo all'analizzatore di distribuzione, questo calcola una stima di fiducia basata sul numero di caratteri frequentemente usati, il numero totale di caratteri, e un rapporto di distribuzione specifico per la lingua. Se la fiducia è abbastanza alta, <code>MultiByteCharSetProber</code> restituisce il risultato a <code>MBCSGroupProber</code>, che lo restituisce a <code>UniversalDetector</code>, che lo restituisce al chiamante.
<p>Il caso del giapponese è più difficile. Gli analizzatori di distribuzione a singolo carattere non sono sempre sufficienti per distinguere tra <code>EUC-JP</code> e <code>SHIFT_JIS</code>, quindi la classe <code>SJISProber</code> (definita in <code>sjisprober.py</code>) usa anche l'analisi di distribuzione a 2 caratteri. <code>SJISContextAnalysis</code> e <code>EUCJPContextAnalysis</code> (entrambe definite in <code>jpcntx.py</code> ed entrambe estensioni della classe <code>JapaneseContextAnalysis</code>) controllano la frequenza dei caratteri dal sillabario Hiragana all'interno del testo. Una volta che è stato elaborato testo a sufficienza, restituiscono un livello di confidenza a <code>SJISProber</code>, che crea entrambi gli analizzatori e restituisce il livello di confidenza più alto a <code>MBCSGroupProber</code>.
<h3 id=how.sb>Codifiche a singolo byte</h3>
<aside>Seriamente, dove'è il mio pony Unicode?</aside>
<p>La sonda per le codifiche a singolo byte, <code>SBCSGroupProber</code> (definita in <code>sbcsgroupprober.py</code>), si occupa anch'essa di gestire un gruppo di altre sonde, una per ogni combinazione di lingua e codifica a singolo byte: <code>windows-1251</code>, <code>KOI8-R</code>, <code>ISO-8859-5</code>, <code>MacCyrillic</code>, <code>IBM855</code>, e <code>IBM866</code> (russo); <code>ISO-8859-7</code> e <code>windows-1253</code> (greco); <code>ISO-8859-5</code> e <code>windows-1251</code> (bulgaro); <code>ISO-8859-2</code> e <code>windows-1250</code> (ungherese); <code>TIS-620</code> (thai); <code>windows-1255</code> e <code>ISO-8859-8</code> (ebraico).
<p><code>SBCSGroupProber</code> passa il testo a queste sonde specifiche per lingua e codifica e controlla i risultati. Queste sonde sono tutte implementate come una singola classe, <code>SingleByteCharSetProber</code> (definita in <code>sbcharsetprober.py</code>), che prende un modello di lingua come argomento. Il modello di lingua definisce la frequenza con cui sequenze di 2 caratteri differenti appaiono in testo tipico. <code>SingleByteCharSetProber</code> elabora il testo e conteggia le sequenze di 2 caratteri più utilizzate. Una volta che ha elaborato testo a sufficienza, calcola un livello di confidenza basato sul numero delle sequenze più utilizzate, il numero totale di caratteri, e un rapporto di distribuzione specifico per lingua.
<p>L'ebraico è trattato come un caso speciale. Se il testo sembra essere ebraico sulla base della analisi di distribuzione a 2 caratteri, <code>HebrewProber</code> (definita in <code>hebrewprober.py</code>) prova a distinguere tra ebraico visuale (dove il testo sorgente è in realtà memorizzato &#8220;all'indietro&#8221; riga-per-riga, e poi visualizzato così com'è in modo da poter essere letto da destra verso sinistra) ed ebraico logico (dove il testo sorgente è memorizzato nell'ordine di lettura e poi riportato da destra verso sinistra dal client). Dato che alcuni caratteri sono codificati in maniera differente a seconda che compaiano nel mezzo o alla fine di una parola, possiamo fare una ipotesi ragionevole a proposito della direzione del testo sorgente, e restituire la codifica appropriata (<code>windows-1255</code> per l'ebraico logico, oppure <code>ISO-8859-8</code> per l'ebraico visuale).
<h3 id=how.windows1252><code>windows-1252</code></h3>
<p>Se <code>UniversalDetector</code> riconosce un carattere <span class=wtf>high-bit</span> nel testo, ma nessuno delle altre sonde per codifiche multi-byte o a singolo byte restituisce un risultato di confidenza, crea una sonda <code>Latin1Prober</code> (definita in <code>latin1prober.py</code>) per cercare di riconoscere testo inglese in una codifica <code>windows-1252</code>. Questo riconscimento è intrinsecamente inaffidabile, perché le lettere inglesi sono rappresentate allo stesso modo in molte codifiche differenti. L'unico modo di distinguere <code>windows-1252</code> è attraverso simboli comunemente usati come virgolette e apostrofi tipografici, simboli di copyright, e simili. <code>Latin1Prober</code> riduce automaticamente la propria stima di confidenza per permettere a sonde più accurate di vincere se è assolutamente possibile.
<h2 id=running2to3>Eseguire <code>2to3</code></h2>
<p>Effettueremo la migrazione del modulo <code>chardet</code> da Python 2 a Python 3. Python 3 viene distribuito con uno script di utilità chiamato <code>2to3</code>, che prende in ingresso il vostro codice sorgente in Python 2 e lo converte automaticamente verso Python 3 tanto quanto gli è possibile. In alcuni casi le modifiche sono semplici &mdash; una funzione è stata rinominata oppure spostata in un modulo differente &mdash; ma in altri casi possono diventare piuttosto complesse. Per avere un'idea di tutto quello che <em>può</em> fare, fate riferimento all'appendice, <a href=convertire-codice-verso-python-3-con-2to3.html>Convertire codice verso Python 3 con <code>2to3</code></a>. In questo capitolo, cominceremo col lanciare <code>2to3</code> sul package <code>chardet</code>, ma come vedrete ci sarà ancora molto lavoro da fare dopo che gli strumenti automatici avranno eseguito i loro incantesimi.
<p>Il package <code>chardet</code> è diviso in molti file diversi, tutti nella stessa directory. Lo script <code>2to3</code> rende facile convertire più file in una volta: basta passargli una directory come argomento a linea di comando, e <code>2to3</code> convertirà ognuno dei file a turno.
<pre class=screen><samp class=p>C:\home\chardet> </samp><kbd>python c:\Python30\Tools\Scripts\2to3.py -w chardet\</kbd>
<samp>RefactoringTool: Skipping implicit fixer: buffer
RefactoringTool: Skipping implicit fixer: idioms
RefactoringTool: Skipping implicit fixer: set_literal
RefactoringTool: Skipping implicit fixer: ws_comma
--- chardet\__init__.py (original)
+++ chardet\__init__.py (refactored)
@@ -18,7 +18,7 @@
 __version__ = "1.0.1"

 def detect(aBuf):
<del>-    import universaldetector</del>
<ins>+    from . import universaldetector</ins>
     u = universaldetector.UniversalDetector()
     u.reset()
     u.feed(aBuf)
--- chardet\big5prober.py (original)
+++ chardet\big5prober.py (refactored)
@@ -25,10 +25,10 @@
 # 02110-1301  USA
 ######################### END LICENSE BLOCK #########################

<del>-from mbcharsetprober import MultiByteCharSetProber</del>
<del>-from codingstatemachine import CodingStateMachine</del>
<del>-from chardistribution import Big5DistributionAnalysis</del>
<del>-from mbcssm import Big5SMModel</del>
<ins>+from .mbcharsetprober import MultiByteCharSetProber</ins>
<ins>+from .codingstatemachine import CodingStateMachine</ins>
<ins>+from .chardistribution import Big5DistributionAnalysis</ins>
<ins>+from .mbcssm import Big5SMModel</ins>

 class Big5Prober(MultiByteCharSetProber):
     def __init__(self):
--- chardet\chardistribution.py (original)
+++ chardet\chardistribution.py (refactored)
@@ -25,12 +25,12 @@
 # 02110-1301  USA
 ######################### END LICENSE BLOCK #########################

<del>-import constants</del>
<del>-from euctwfreq import EUCTWCharToFreqOrder, EUCTW_TABLE_SIZE, EUCTW_TYPICAL_DISTRIBUTION_RATIO</del>
<del>-from euckrfreq import EUCKRCharToFreqOrder, EUCKR_TABLE_SIZE, EUCKR_TYPICAL_DISTRIBUTION_RATIO</del>
<del>-from gb2312freq import GB2312CharToFreqOrder, GB2312_TABLE_SIZE, GB2312_TYPICAL_DISTRIBUTION_RATIO</del>
<del>-from big5freq import Big5CharToFreqOrder, BIG5_TABLE_SIZE, BIG5_TYPICAL_DISTRIBUTION_RATIO</del>
<del>-from jisfreq import JISCharToFreqOrder, JIS_TABLE_SIZE, JIS_TYPICAL_DISTRIBUTION_RATIO</del>
<ins>+from . import constants</ins>
<ins>+from .euctwfreq import EUCTWCharToFreqOrder, EUCTW_TABLE_SIZE, EUCTW_TYPICAL_DISTRIBUTION_RATIO</ins>
<ins>+from .euckrfreq import EUCKRCharToFreqOrder, EUCKR_TABLE_SIZE, EUCKR_TYPICAL_DISTRIBUTION_RATIO</ins>
<ins>+from .gb2312freq import GB2312CharToFreqOrder, GB2312_TABLE_SIZE, GB2312_TYPICAL_DISTRIBUTION_RATIO</ins>
<ins>+from .big5freq import Big5CharToFreqOrder, BIG5_TABLE_SIZE, BIG5_TYPICAL_DISTRIBUTION_RATIO</ins>
<ins>+from .jisfreq import JISCharToFreqOrder, JIS_TABLE_SIZE, JIS_TYPICAL_DISTRIBUTION_RATIO</ins>

 ENOUGH_DATA_THRESHOLD = 1024
 SURE_YES = 0.99
--- chardet\charsetgroupprober.py (original)
+++ chardet\charsetgroupprober.py (refactored)
@@ -26,7 +26,7 @@
 ######################### END LICENSE BLOCK #########################

 import constants, sys
<del>-from charsetprober import CharSetProber</del>
<ins>+from .charsetprober import CharSetProber</ins>

 class CharSetGroupProber(CharSetProber):
     def __init__(self):
--- chardet\codingstatemachine.py (original)
+++ chardet\codingstatemachine.py (refactored)
@@ -25,7 +25,7 @@
 # 02110-1301  USA
 ######################### END LICENSE BLOCK #########################

<del>-from constants import eStart, eError, eItsMe</del>
<ins>+from .constants import eStart, eError, eItsMe</ins>

 class CodingStateMachine:
     def __init__(self, sm):
--- chardet\constants.py (original)
+++ chardet\constants.py (refactored)
@@ -38,10 +38,10 @@

 SHORTCUT_THRESHOLD = 0.95

<del>-import __builtin__</del>
<ins>+import builtins</ins>
 if not hasattr(__builtin__, 'False'):
     False = 0
     True = 1
 else:
<del>-    False = __builtin__.False</del>
<del>-    True = __builtin__.True</del>
<ins>+    False = builtins.False</ins>
<ins>+    True = builtins.True</ins>
--- chardet\escprober.py (original)
+++ chardet\escprober.py (refactored)
@@ -26,9 +26,9 @@
 ######################### END LICENSE BLOCK #########################

 import constants, sys
<del>-from escsm import HZSMModel, ISO2022CNSMModel, ISO2022JPSMModel, ISO2022KRSMModel</del>
<del>-from charsetprober import CharSetProber</del>
<del>-from codingstatemachine import CodingStateMachine</del>
<ins>+from .escsm import HZSMModel, ISO2022CNSMModel, ISO2022JPSMModel, ISO2022KRSMModel</ins>
<ins>+from .charsetprober import CharSetProber</ins>
<ins>+from .codingstatemachine import CodingStateMachine</ins>

 class EscCharSetProber(CharSetProber):
     def __init__(self):
--- chardet\escsm.py (original)
+++ chardet\escsm.py (refactored)
@@ -25,7 +25,7 @@
 # 02110-1301  USA
 ######################### END LICENSE BLOCK #########################

<del>-from constants import eStart, eError, eItsMe</del>
<ins>+from .constants import eStart, eError, eItsMe</ins>

 HZ_cls = ( \
 1,0,0,0,0,0,0,0,  # 00 - 07
--- chardet\eucjpprober.py (original)
+++ chardet\eucjpprober.py (refactored)
@@ -26,12 +26,12 @@
 ######################### END LICENSE BLOCK #########################

 import constants, sys
<del>-from constants import eStart, eError, eItsMe</del>
<del>-from mbcharsetprober import MultiByteCharSetProber</del>
<del>-from codingstatemachine import CodingStateMachine</del>
<del>-from chardistribution import EUCJPDistributionAnalysis</del>
<del>-from jpcntx import EUCJPContextAnalysis</del>
<del>-from mbcssm import EUCJPSMModel</del>
<ins>+from .constants import eStart, eError, eItsMe</ins>
<ins>+from .mbcharsetprober import MultiByteCharSetProber</ins>
<ins>+from .codingstatemachine import CodingStateMachine</ins>
<ins>+from .chardistribution import EUCJPDistributionAnalysis</ins>
<ins>+from .jpcntx import EUCJPContextAnalysis</ins>
<ins>+from .mbcssm import EUCJPSMModel</ins>

 class EUCJPProber(MultiByteCharSetProber):
     def __init__(self):
--- chardet\euckrprober.py (original)
+++ chardet\euckrprober.py (refactored)
@@ -25,10 +25,10 @@
 # 02110-1301  USA
 ######################### END LICENSE BLOCK #########################

<del>-from mbcharsetprober import MultiByteCharSetProber</del>
<del>-from codingstatemachine import CodingStateMachine</del>
<del>-from chardistribution import EUCKRDistributionAnalysis</del>
<del>-from mbcssm import EUCKRSMModel</del>
<ins>+from .mbcharsetprober import MultiByteCharSetProber</ins>
<ins>+from .codingstatemachine import CodingStateMachine</ins>
<ins>+from .chardistribution import EUCKRDistributionAnalysis</ins>
<ins>+from .mbcssm import EUCKRSMModel</ins>

 class EUCKRProber(MultiByteCharSetProber):
     def __init__(self):
--- chardet\euctwprober.py (original)
+++ chardet\euctwprober.py (refactored)
@@ -25,10 +25,10 @@
 # 02110-1301  USA
 ######################### END LICENSE BLOCK #########################

<del>-from mbcharsetprober import MultiByteCharSetProber</del>
<del>-from codingstatemachine import CodingStateMachine</del>
<del>-from chardistribution import EUCTWDistributionAnalysis</del>
<del>-from mbcssm import EUCTWSMModel</del>
<ins>+from .mbcharsetprober import MultiByteCharSetProber</ins>
<ins>+from .codingstatemachine import CodingStateMachine</ins>
<ins>+from .chardistribution import EUCTWDistributionAnalysis</ins>
<ins>+from .mbcssm import EUCTWSMModel</ins>

 class EUCTWProber(MultiByteCharSetProber):
     def __init__(self):
--- chardet\gb2312prober.py (original)
+++ chardet\gb2312prober.py (refactored)
@@ -25,10 +25,10 @@
 # 02110-1301  USA
 ######################### END LICENSE BLOCK #########################

<del>-from mbcharsetprober import MultiByteCharSetProber</del>
<del>-from codingstatemachine import CodingStateMachine</del>
<del>-from chardistribution import GB2312DistributionAnalysis</del>
<del>-from mbcssm import GB2312SMModel</del>
<ins>+from .mbcharsetprober import MultiByteCharSetProber</ins>
<ins>+from .codingstatemachine import CodingStateMachine</ins>
<ins>+from .chardistribution import GB2312DistributionAnalysis</ins>
<ins>+from .mbcssm import GB2312SMModel</ins>

 class GB2312Prober(MultiByteCharSetProber):
     def __init__(self):
--- chardet\hebrewprober.py (original)
+++ chardet\hebrewprober.py (refactored)
@@ -25,8 +25,8 @@
 # 02110-1301  USA
 ######################### END LICENSE BLOCK #########################

<del>-from charsetprober import CharSetProber</del>
<del>-import constants</del>
<ins>+from .charsetprober import CharSetProber</ins>
<ins>+from . import constants</ins>

 # This prober doesn't actually recognize a language or a charset.
 # It is a helper prober for the use of the Hebrew model probers
--- chardet\jpcntx.py (original)
+++ chardet\jpcntx.py (refactored)
@@ -25,7 +25,7 @@
 # 02110-1301  USA
 ######################### END LICENSE BLOCK #########################

<del>-import constants</del>
<ins>+from . import constants</ins>

 NUM_OF_CATEGORY = 6
 DONT_KNOW = -1
--- chardet\langbulgarianmodel.py (original)
+++ chardet\langbulgarianmodel.py (refactored)
@@ -25,7 +25,7 @@
 # 02110-1301  USA
 ######################### END LICENSE BLOCK #########################

<del>-import constants</del>
<ins>+from . import constants</ins>

 # 255: Control characters that usually does not exist in any text
 # 254: Carriage/Return
--- chardet\langcyrillicmodel.py (original)
+++ chardet\langcyrillicmodel.py (refactored)
@@ -25,7 +25,7 @@
 # 02110-1301  USA
 ######################### END LICENSE BLOCK #########################

<del>-import constants</del>
<ins>+from . import constants</ins>

 # KOI8-R language model
 # Character Mapping Table:
--- chardet\langgreekmodel.py (original)
+++ chardet\langgreekmodel.py (refactored)
@@ -25,7 +25,7 @@
 # 02110-1301  USA
 ######################### END LICENSE BLOCK #########################

<del>-import constants</del>
<ins>+from . import constants</ins>

 # 255: Control characters that usually does not exist in any text
 # 254: Carriage/Return
--- chardet\langhebrewmodel.py (original)
+++ chardet\langhebrewmodel.py (refactored)
@@ -27,7 +27,7 @@
 # 02110-1301  USA
 ######################### END LICENSE BLOCK #########################

<del>-import constants</del>
<ins>+from . import constants</ins>

 # 255: Control characters that usually does not exist in any text
 # 254: Carriage/Return
--- chardet\langhungarianmodel.py (original)
+++ chardet\langhungarianmodel.py (refactored)
@@ -25,7 +25,7 @@
 # 02110-1301  USA
 ######################### END LICENSE BLOCK #########################

<del>-import constants</del>
<ins>+from . import constants</ins>

 # 255: Control characters that usually does not exist in any text
 # 254: Carriage/Return
--- chardet\langthaimodel.py (original)
+++ chardet\langthaimodel.py (refactored)
@@ -25,7 +25,7 @@
 # 02110-1301  USA
 ######################### END LICENSE BLOCK #########################

<del>-import constants</del>
<ins>+from . import constants</ins>

 # 255: Control characters that usually does not exist in any text
 # 254: Carriage/Return
--- chardet\latin1prober.py (original)
+++ chardet\latin1prober.py (refactored)
@@ -26,8 +26,8 @@
 # 02110-1301  USA
 ######################### END LICENSE BLOCK #########################

<del>-from charsetprober import CharSetProber</del>
<del>-import constants</del>
<ins>+from .charsetprober import CharSetProber</ins>
<ins>+from . import constants</ins>
 import operator

 FREQ_CAT_NUM = 4
--- chardet\mbcharsetprober.py (original)
+++ chardet\mbcharsetprober.py (refactored)
@@ -28,8 +28,8 @@
 ######################### END LICENSE BLOCK #########################

 import constants, sys
<del>-from constants import eStart, eError, eItsMe</del>
<del>-from charsetprober import CharSetProber</del>
<ins>+from .constants import eStart, eError, eItsMe</ins>
<ins>+from .charsetprober import CharSetProber</ins>

 class MultiByteCharSetProber(CharSetProber):
     def __init__(self):
--- chardet\mbcsgroupprober.py (original)
+++ chardet\mbcsgroupprober.py (refactored)
@@ -27,14 +27,14 @@
 # 02110-1301  USA
 ######################### END LICENSE BLOCK #########################

<del>-from charsetgroupprober import CharSetGroupProber</del>
<del>-from utf8prober import UTF8Prober</del>
<del>-from sjisprober import SJISProber</del>
<del>-from eucjpprober import EUCJPProber</del>
<del>-from gb2312prober import GB2312Prober</del>
<del>-from euckrprober import EUCKRProber</del>
<del>-from big5prober import Big5Prober</del>
<del>-from euctwprober import EUCTWProber</del>
<ins>+from .charsetgroupprober import CharSetGroupProber</ins>
<ins>+from .utf8prober import UTF8Prober</ins>
<ins>+from .sjisprober import SJISProber</ins>
<ins>+from .eucjpprober import EUCJPProber</ins>
<ins>+from .gb2312prober import GB2312Prober</ins>
<ins>+from .euckrprober import EUCKRProber</ins>
<ins>+from .big5prober import Big5Prober</ins>
<ins>+from .euctwprober import EUCTWProber</ins>

 class MBCSGroupProber(CharSetGroupProber):
     def __init__(self):
--- chardet\mbcssm.py (original)
+++ chardet\mbcssm.py (refactored)
@@ -25,7 +25,7 @@
 # 02110-1301  USA
 ######################### END LICENSE BLOCK #########################

<del>-from constants import eStart, eError, eItsMe</del>
<ins>+from .constants import eStart, eError, eItsMe</ins>

 # BIG5

--- chardet\sbcharsetprober.py (original)
+++ chardet\sbcharsetprober.py (refactored)
@@ -27,7 +27,7 @@
 ######################### END LICENSE BLOCK #########################

 import constants, sys
<del>-from charsetprober import CharSetProber</del>
<ins>+from .charsetprober import CharSetProber</ins>

 SAMPLE_SIZE = 64
 SB_ENOUGH_REL_THRESHOLD = 1024
--- chardet\sbcsgroupprober.py (original)
+++ chardet\sbcsgroupprober.py (refactored)
@@ -27,15 +27,15 @@
 ######################### END LICENSE BLOCK #########################

 import constants, sys
<del>-from charsetgroupprober import CharSetGroupProber</del>
<del>-from sbcharsetprober import SingleByteCharSetProber</del>
<del>-from langcyrillicmodel import Win1251CyrillicModel, Koi8rModel, Latin5CyrillicModel, MacCyrillicModel, Ibm866Model, Ibm855Model</del>
<del>-from langgreekmodel import Latin7GreekModel, Win1253GreekModel</del>
<del>-from langbulgarianmodel import Latin5BulgarianModel, Win1251BulgarianModel</del>
<del>-from langhungarianmodel import Latin2HungarianModel, Win1250HungarianModel</del>
<del>-from langthaimodel import TIS620ThaiModel</del>
<del>-from langhebrewmodel import Win1255HebrewModel</del>
<del>-from hebrewprober import HebrewProber</del>
<ins>+from .charsetgroupprober import CharSetGroupProber</ins>
<ins>+from .sbcharsetprober import SingleByteCharSetProber</ins>
<ins>+from .langcyrillicmodel import Win1251CyrillicModel, Koi8rModel, Latin5CyrillicModel, MacCyrillicModel, Ibm866Model, Ibm855Model</ins>
<ins>+from .langgreekmodel import Latin7GreekModel, Win1253GreekModel</ins>
<ins>+from .langbulgarianmodel import Latin5BulgarianModel, Win1251BulgarianModel</ins>
<ins>+from .langhungarianmodel import Latin2HungarianModel, Win1250HungarianModel</ins>
<ins>+from .langthaimodel import TIS620ThaiModel</ins>
<ins>+from .langhebrewmodel import Win1255HebrewModel</ins>
<ins>+from .hebrewprober import HebrewProber</ins>

 class SBCSGroupProber(CharSetGroupProber):
     def __init__(self):
--- chardet\sjisprober.py (original)
+++ chardet\sjisprober.py (refactored)
@@ -25,13 +25,13 @@
 # 02110-1301  USA
 ######################### END LICENSE BLOCK #########################

<del>-from mbcharsetprober import MultiByteCharSetProber</del>
<del>-from codingstatemachine import CodingStateMachine</del>
<del>-from chardistribution import SJISDistributionAnalysis</del>
<del>-from jpcntx import SJISContextAnalysis</del>
<del>-from mbcssm import SJISSMModel</del>
<ins>+from .mbcharsetprober import MultiByteCharSetProber</ins>
<ins>+from .codingstatemachine import CodingStateMachine</ins>
<ins>+from .chardistribution import SJISDistributionAnalysis</ins>
<ins>+from .jpcntx import SJISContextAnalysis</ins>
<ins>+from .mbcssm import SJISSMModel</ins>
 import constants, sys
<del>-from constants import eStart, eError, eItsMe</del>
<ins>+from .constants import eStart, eError, eItsMe</ins>

 class SJISProber(MultiByteCharSetProber):
     def __init__(self):
--- chardet\universaldetector.py (original)
+++ chardet\universaldetector.py (refactored)
@@ -27,10 +27,10 @@
 ######################### END LICENSE BLOCK #########################

 import constants, sys
<del>-from latin1prober import Latin1Prober # windows-1252</del>
<del>-from mbcsgroupprober import MBCSGroupProber # multi-byte character sets</del>
<del>-from sbcsgroupprober import SBCSGroupProber # single-byte character sets</del>
<del>-from escprober import EscCharSetProber # ISO-2122, etc.</del>
<ins>+from .latin1prober import Latin1Prober # windows-1252</ins>
<ins>+from .mbcsgroupprober import MBCSGroupProber # multi-byte character sets</ins>
<ins>+from .sbcsgroupprober import SBCSGroupProber # single-byte character sets</ins>
<ins>+from .escprober import EscCharSetProber # ISO-2122, etc.</ins>
 import re

 MINIMUM_THRESHOLD = 0.20
--- chardet\utf8prober.py (original)
+++ chardet\utf8prober.py (refactored)
@@ -26,10 +26,10 @@
 ######################### END LICENSE BLOCK #########################

 import constants, sys
<del>-from constants import eStart, eError, eItsMe</del>
<del>-from charsetprober import CharSetProber</del>
<del>-from codingstatemachine import CodingStateMachine</del>
<del>-from mbcssm import UTF8SMModel</del>
<ins>+from .constants import eStart, eError, eItsMe</ins>
<ins>+from .charsetprober import CharSetProber</ins>
<ins>+from .codingstatemachine import CodingStateMachine</ins>
<ins>+from .mbcssm import UTF8SMModel</ins>

 ONE_CHAR_PROB = 0.5

RefactoringTool: Files that were modified:
RefactoringTool: chardet\__init__.py
RefactoringTool: chardet\big5prober.py
RefactoringTool: chardet\chardistribution.py
RefactoringTool: chardet\charsetgroupprober.py
RefactoringTool: chardet\codingstatemachine.py
RefactoringTool: chardet\constants.py
RefactoringTool: chardet\escprober.py
RefactoringTool: chardet\escsm.py
RefactoringTool: chardet\eucjpprober.py
RefactoringTool: chardet\euckrprober.py
RefactoringTool: chardet\euctwprober.py
RefactoringTool: chardet\gb2312prober.py
RefactoringTool: chardet\hebrewprober.py
RefactoringTool: chardet\jpcntx.py
RefactoringTool: chardet\langbulgarianmodel.py
RefactoringTool: chardet\langcyrillicmodel.py
RefactoringTool: chardet\langgreekmodel.py
RefactoringTool: chardet\langhebrewmodel.py
RefactoringTool: chardet\langhungarianmodel.py
RefactoringTool: chardet\langthaimodel.py
RefactoringTool: chardet\latin1prober.py
RefactoringTool: chardet\mbcharsetprober.py
RefactoringTool: chardet\mbcsgroupprober.py
RefactoringTool: chardet\mbcssm.py
RefactoringTool: chardet\sbcharsetprober.py
RefactoringTool: chardet\sbcsgroupprober.py
RefactoringTool: chardet\sjisprober.py
RefactoringTool: chardet\universaldetector.py
RefactoringTool: chardet\utf8prober.py</samp></pre>
<p>Ora eseguiamo lo script <code>2to3</code> sulla <span class=wtf>harness</span> di collaudo, <code>test.py</code>.
<pre class=screen><samp class=p>C:\home\chardet> </samp><kbd>python c:\Python30\Tools\Scripts\2to3.py -w test.py</kbd>
<samp>RefactoringTool: Skipping implicit fixer: buffer
RefactoringTool: Skipping implicit fixer: idioms
RefactoringTool: Skipping implicit fixer: set_literal
RefactoringTool: Skipping implicit fixer: ws_comma
--- test.py (original)
+++ test.py (refactored)
@@ -4,7 +4,7 @@
 count = 0
 u = UniversalDetector()
 for f in glob.glob(sys.argv[1]):
<del>-    print f.ljust(60),</del>
<ins>+    print(f.ljust(60), end=' ')</ins>
     u.reset()
     for line in file(f, 'rb'):
         u.feed(line)
@@ -12,8 +12,8 @@
     u.close()
     result = u.result
     if result['encoding']:
<del>-        print result['encoding'], 'with confidence', result['confidence']</del>
<ins>+        print(result['encoding'], 'with confidence', result['confidence'])</ins>
     else:
<del>-        print '******** no result'</del>
<ins>+        print('******** no result')</ins>
     count += 1
<del>-print count, 'tests'</del>
<ins>+print(count, 'tests')</ins>
RefactoringTool: Files that were modified:
RefactoringTool: test.py</samp></pre>
<p><span class=fixme>[FIXME explain the difference in import syntax]</span>
<p>Ebbene, non è stato così difficile. Solo alcune istruzioni di <code>import</code> e <code>print</code> da convertire. &Egrave; il momento di eseguire la nuova versione. Pensate che funzionerà?
<h2 id=manual>Risolvere quello che <code>2to3</code> non può</h2>
<h3 id=falseisinvalidsyntax><code>False</code> è invalid syntax</h3>
<aside>Avete i test, giusto?</aside>
<p>E ora, il collaudo vero e proprio: lanciare la <span class=wtf>harness</span> di test contro la <span class=wtf>test suite</span>. Dato che la <span class=wtf>test suite</span> è stata progettata per coprire tutti i possibili percorsi di esecuzione nel codice, è un buon modo di collaudare il codice convertito per assicurarsi che non ci sia alcun bug in agguato da qualche parte.
<pre class=screen><samp class=p>C:\home\chardet> </samp><kbd>python test.py tests\*\*</kbd>
<samp class=traceback>Traceback (most recent call last):
  File "test.py", line 1, in &lt;module>
    from chardet.universaldetector import UniversalDetector
  File "C:\home\chardet\chardet\universaldetector.py", line 51
    self.done = constants.False
                              ^
SyntaxError: invalid syntax</samp></pre>
<p>Hmmm, un piccolo intoppo. In Python 3, <code>False</code> è una parola riservata, e quindi non potete usarla come nome di variabile. Diamo una occhiata a <code>constants.py</code> per vedere dov'è definita. Ecco la versione orginale da <code>constants.py</code>, prima che lo script <code>2to3</code> la cambiasse:
<pre><code>import __builtin__
if not hasattr(__builtin__, 'False'):
    False = 0
    True = 1
else:
    False = __builtin__.False
    True = __builtin__.True</code></pre>
<p>Questo frammento di codice è progettato per permettere a questa libreria di venire eseguita dalle versioni più vecchie di Python 2. Prima della versione 2.3 <span class=fixme>[FIXME-LINK]</span>, Python non aveva alcun tipo <code>Boolean</code>. Questo codice riconosce l'assenza delle costanti built-in <code>True</code> e <code>False</code>, e le definisce nel caso sia necessario.
<p>Comunque, Python 3 avrà sempre un tipo <code>Boolean</code>, quindi questo intero frammento di codice è superfluo. La soluzione più semplice consiste nel sostituire tutte le istanze di <code>constants.True</code> e <code>constants.False</code> con <code>True</code> e <code>False</code>, rispettivamente, e poi cancellare questo codice ormai inutile da <code>constants.py</code>.
<p>Così questa riga <code>universaldetector.py</code>:
<pre><code>self.done = constants.False</code></pre>
<p>Diventa
<pre><code>self.done = False</code></pre>
<p>Aaah, non siete soddisfatti? Il codice è più corto e già più leggibile.
<h3 id=nomodulenamedconstants>No module named <code>constants</code></h3>
<p>&Egrave; il momento di eseguire nuovamente <code>test.py</code> e vedere fino a dove riesce ad arrivare.
<pre class=screen><samp class=p>C:\home\chardet> </samp><kbd>python test.py tests\*\*</kbd>
<samp class=traceback>Traceback (most recent call last):
  File "test.py", line 1, in &lt;module>
    from chardet.universaldetector import UniversalDetector
  File "C:\home\chardet\chardet\universaldetector.py", line 29, in &lt;module>
    import constants, sys
ImportError: No module named constants</samp></pre>
<p>Cosa dice? Nessun modulo chiamato <code>constants</code>? Ma certo che c'è un modulo chiamato <code>constants</code>. &hellip;Oh aspettate, no non c'è. Ricordate quando lo script <code>2to3</code> ha risolto tutte quelle istruzioni di <code>import</code>? Questa libreria ha un sacco di <code>import</code> relativi &mdash; cioè, moduli che importano altri moduli nell'ambito della libreria. In Python 3, tutte le istruzioni di <code>import</code> sono assolute di default <span class=fixme>[FIXME-LINK PEP 0328]</span>. Per importare un modulo in maniera relativa, avete bisogno di scrivere qualcosa come questo:
<pre><code>from . import constants</code></pre>
<p>Ma aspettate. Non doveva essere lo script <code>2to3</code> a curarsi di queste cose per voi? Be', lo ha fatto, ma la particolare istruzione di <code>import</code> che ha generato l'errore combina due differenti tipi di importazione in una riga: una importazione relativa del modulo <code>constants</code> all'interno della libreria, e una importazione assoluta del modulo <code>sys</code> che è preinstallato nella libreria standard di Python. In Python 2, potevate combinare questi due in un'unica istruzione <code>import</code>. In Python 3, non potete, e lo script <code>2to3</code> non è abbastanza scaltro da spezzare l'istruzione di <code>import</code> in due.
<p>La soluzione consiste nel dividere l'istruzione di <code>import</code> manualmente. Così questa doppia istruzione di <code>import</code>:
<pre><code>import constants, sys</code></pre>
<p>Deve diventare due istruzioni di <code>import</code> separate:
<pre><code>from . import constants
import sys</code></pre>
<p>Ci sono variazioni di questo problema sparse in tutta la libreria <code>chardet</code>. In alcuni posti è &#8220;<code>import constants, sys</code>&#8221;; in altri posti, è &#8220;<code>import constants, re</code>&#8221;. La soluzione è la stessa: dividete manualmente l'istruzione di <code>import</code> in due righe, una per quella relativa, l'altra per quella assoluta.
<p>Procediamo!
<h3 id=namefileisnotdefined>Name <var>'file'</var> is not defined</h3>
<aside>open() è il nuovo file(). PapayaWhip è il nuovo nero.</aside>
<p>Ed eccoci ancora qui, a lanciare <code>test.py</code> per provare a eseguire i nostri test&hellip;</p>
<pre class=screen><samp class=p>C:\home\chardet> </samp><kbd>python test.py tests\*\*</kbd>
<samp>tests\ascii\howto.diveintomark.org.xml</samp>
<samp class=traceback>Traceback (most recent call last):
  File "test.py", line 9, in &lt;module>
    for line in file(f, 'rb'):
NameError: name 'file' is not defined</samp></pre>
<p>Questo mi ha sorpreso, perché ho usato questo idioma fin da quando riesco a ricordare. In Python 2, la funzione globale <var>file()</var> era un alias per <var>open()</var>, che era il modo standard di aprire i file per leggerli. In Python 3, l'intero sistema per la lettura e la scrittura dei file è stato rifattorizzato nel modulo <code>io</code>. <span class=fixme>[FIXME-LINK PEP 3116]</span> Tratterò del nuovo modulo di I/O con maggiori dettagli nel Capitolo <span class=fixme>FIXME</span>, ma per ora la cosa importante è che la funzione globale <var>file()</var> non esiste più. Comunque, la funzione <var>open()</var> esiste ancora. (Tecnicamente, è un alias per <var>io.open()</var>, ma non preoccupatevi di questo adesso.)
<p>Quindi, la soluzione più semplice al problema della mancanza di <var>file()</var> è chiamare <var>open()</var> al suo posto:
<pre><code>for line in open(f, 'rb'):</code></pre>
<p>E questo è tutto quello che ho da dire in merito.
<h3 id=cantuseastringpattern>Can't use a string pattern on a bytes-like object</h3>
<p>Ora le cose cominciano a diventare interessanti. E per &#8220;interessanti,&#8221; voglio dire &#8220;incasinate come l'inferno.&#8221;
<pre class=screen><samp class=p>C:\home\chardet> </samp><kbd>python test.py tests\*\*</kbd>
<samp>tests\ascii\howto.diveintomark.org.xml</samp>
<samp class=traceback>Traceback (most recent call last):
  File "test.py", line 10, in &lt;module>
    u.feed(line)
  File "C:\home\chardet\chardet\universaldetector.py", line 98, in feed
    if self._highBitDetector.search(aBuf):
TypeError: can't use a string pattern on a bytes-like object</samp></pre>
<p>Per correggere questo, diamo un'occhiata a cos'è <var>self._highBitDetector</var>. &Egrave; definito nel metodo <code>__init__()</code> della classe <var>UniversalDetector</var>:
<pre><code>class UniversalDetector:
    def __init__(self):
        self._highBitDetector = re.compile(r'[\x80-\xFF]')</code></pre>
<p>Questo precompila una espressione regolare progettata per trovare caratteri di tipo non-<abbr>ASCII</abbr> nell'intervallo 128&ndash;255 (0x80&ndash;0xFF). Aspettate, non è proprio esatto; devo essere più preciso nella mia terminologia. Questo pattern è usato per trovare <em>byte</em> di tipo non-<abbr>ASCII</abbr> nell'intervallo 128&ndash;255.
<p>E il problema è proprio qui.
<p>In Python 2, una stringa era un array di byte la cui codifica di carattere era <span class=wtf>tracked</span> separatamente. Se volevate che Python 2 tenesse traccia della codifica di carattere, dovevate usare una stringa di tipo Unicode (<code>u''</code>). Ma in Python 3, una stringa è sempre quello che Python 2 chiamava stringa di tipo Unicode &mdash; cioè, un array di caratteri Unicode (possibilmente con lunghezze diverse in termini di byte). Dato che questa espressione regolare è definita come un pattern in una stringa, può essere usata solo per fare ricerche in una stringa &mdash; ancora, un array di caratteri. Ma ciò in cui stiamo cercando non è una stringa, bensì un array di byte. Dando un'occhiata alla <span class=wtf>traceback</span>, questo errore è apparso in <code>universaldetector.py</code>:
<pre><code>def feed(self, aBuf):
    .
    .
    .
    if self._mInputState == ePureAscii:
        if self._highBitDetector.search(aBuf):</code></pre>
<p>E cos'è <var>aBuf</var>? Torniamo ancora più indietro al luogo che invoca <code>UniversalDetector.feed()</code>. Un luogo che lo invoca è la <span class=wtf>harness</span> di collaudo, <code>test.py</code>.
<pre><code>u = UniversalDetector()
.
.
.
for line in open(f, 'rb'):
    u.feed(line)</code></pre>
<aside>Non un vettore di caratteri, ma un vettore di byte.</aside>
<p>E qui troviamo la nostra risposta: nel metodo <code>UniversalDetector.feed()</code>, <var>aBuf</var> è una riga letta da un file su disco. Guardate attentamente i parametri utilizzati per aprire il file: <code>'rb'</code>. <code>'r'</code> sta per &#8220;read&#8221;, lettura; OK, grazie tante, stiamo leggendo il file. Ah, ma <code>'b'</code> sta per &#8220;binary&#8221;, binario. Senza il flag <code>'b'</code>, questo ciclo <code>for</code> leggerebbe il file, riga per riga, e convertirebbe ogni riga in una stringa &mdash; un array di caratteri Unicode &mdash; in accordo con la codifica di carattere di default del sistema. (Potreste <span class=wtf>override</span> la codifica del sistema con un altro parametro di <var>open()</var>, ma non preoccupatevi di questo adesso.) Ma con il flag <code>'b'</code>, questo ciclo <code>for</code> legge il file, riga per riga, e memorizza ogni riga esattamente come appare nel file, come un array di byte. Quell'array di byte viene passato a <code>UniversalDetector.feed()</code>, e alla fine viene passato alla espressione regolare precompilata, <var>self._highBitDetector</var>, per cercare i&hellip; caratteri <span class=wtf>high-bit</span>. Ma non abbiamo caratteri. Abbiamo byte. Oops.
<p>Quello su cui abbiamo bisogno che l'espressione regolare effettui la ricerca non è un array di caratteri, ma un array di byte.
<p>Una volta che realizzate questo, la soluzione non è difficile. Le espressioni regolari definite come stringhe possono effettuare ricerche sulle stringe. Le espressioni regolari definite come array di byte possono effettuare ricerche sugli array di byte. Per definire un pattern come un array di byte, cambiamo semplicemente il tipo dell'argomento che usiamo per definire l'espressione regolare ad array di byte. (C'è un altro caso di questo stesso problema, proprio nella riga successiva.)
<pre><code>  class UniversalDetector:
      def __init__(self):
<del>-         self._highBitDetector = re.compile(r'[\x80-\xFF]')</del>
<del>-         self._escDetector = re.compile(r'(\033|~{)')</del>
<ins>+         self._highBitDetector = re.compile(b'[\x80-\xFF]')</ins>
<ins>+         self._escDetector = re.compile(b'(\033|~{)')</ins>
          self._mEscCharSetProber = None
          self._mCharSetProbers = []
          self.reset()</code></pre>
<p>Una ricerca sull'intera base di codice rivela altri due utilizzi del modulo <code>re</code>, in <code>charsetprober.py</code>. Ancora, il codice definisce espressioni regolari come stringhe ma le esegue su <var>aBuf</var>, che è un array di byte. La soluzione è la stessa: definire i pattern di espressione regolare come array di byte.
<pre><code>  class CharSetProber:
      .
      .
      .
      def filter_high_bit_only(self, aBuf):
<del>-         aBuf = re.sub(r'([\x00-\x7F])+', ' ', aBuf)</del>
<ins>+         aBuf = re.sub(b'([\x00-\x7F])+', b' ', aBuf)</ins>
          return aBuf
    
      def filter_without_english_letters(self, aBuf):
<del>-         aBuf = re.sub(r'([A-Za-z])+', ' ', aBuf)</del>
<ins>+         aBuf = re.sub(b'([A-Za-z])+', b' ', aBuf)</ins>
          return aBuf</code></pre>
        
<h3 id=cantconvertbytesobject>Can't convert <code>'bytes'</code> object to str implicitly</h3>
<p>Sempre più curioso&hellip;
<pre class=screen><samp class=p>C:\home\chardet> </samp><kbd>python test.py tests\*\*</kbd>
<samp>tests\ascii\howto.diveintomark.org.xml</samp>
<samp class=traceback>Traceback (most recent call last):
  File "test.py", line 10, in &lt;module>
    u.feed(line)
  File "C:\home\chardet\chardet\universaldetector.py", line 100, in feed
    elif (self._mInputState == ePureAscii) and self._escDetector.search(self._mLastChar + aBuf):
TypeError: Can't convert 'bytes' object to str implicitly</samp></pre>
<p>Qui c'è uno sfortunato scontro tra stile di codifica e l'interprete Python. L'errore di tipo <code>TypeError</code> potrebbe essere dovunque su quella riga, ma la <span class=wtf>traceback</span> non vi dice esattamente dov'è. Potrebbe essere nella prima condizione o nella seconda, e la <span class=wtf>traceback</span> sarebbe la stessa. Per circoscrivere l'errore, dovete spezzare a metà la riga, in questo modo:
<pre><code>elif (self._mInputState == ePureAscii) and \
    self._escDetector.search(self._mLastChar + aBuf):</code></pre>
<p>And re-run the test:</p>
<pre class=screen><samp class=p>C:\home\chardet> </samp><kbd>python test.py tests\*\*</kbd>
<samp>tests\ascii\howto.diveintomark.org.xml</samp>
<samp class=traceback>Traceback (most recent call last):
  File "test.py", line 10, in &lt;module>
    u.feed(line)
  File "C:\home\chardet\chardet\universaldetector.py", line 101, in feed
    self._escDetector.search(self._mLastChar + aBuf):
TypeError: Can't convert 'bytes' object to str implicitly</samp></pre>
<p>Aha! Il problema non era nella prima condizione (<code>self._mInputState == ePureAscii</code>) ma nella seconda. Quindi cosa potrebbe causare un <code>TypeError</code> lì? Forse state pensando che il metodo <code>search()</code> si aspetti un valore di tipo differente, ma quello non genererebbe questa <span class=wtf>traceback</span>. Le funzioni Python possono accettare qualsiasi valore; se passate il numero corretto di argomenti, la funzione eseguirà. Potrebbe <em>fallire</em> se le passate un valore di tipo differente rispetto a quello che si aspetta, ma se questo fosse successo, la <span class=wtf>traceback</span> punterebbe da qualche parte all'interno della funzione. Ma questa <span class=wtf>traceback</span> dice che l'interprete non è mai arrivato tanto lontano da chiamare il metodo <code>search()</code>. Quindi il problema deve essere in quella operazione <code>+</code>, dato che sta cercando di costruire un valore che alla fine verrà passato al metodo <code>search()</code>.
<p>Sappiamo da una <a href=#cantuseastringpattern>correzione precedente</a> che <var>aBuf</var> è un array di byte. Quindi cos'è <code>self._mLastChar</code>? &Egrave; una variabile di istanza, definita nel metodo <code>reset()</code>, che viene effettivamente chiamato dal metodo <code>__init__()</code>.
<pre><code>class UniversalDetector:
    def __init__(self):
        self._highBitDetector = re.compile(b'[\x80-\xFF]')
        self._escDetector = re.compile(b'(\033|~{)')
        self._mEscCharSetProber = None
        self._mCharSetProbers = []
<mark>        self.reset()</mark>

    def reset(self):
        self.result = {'encoding': None, 'confidence': 0.0}
        self.done = False
        self._mStart = True
        self._mGotData = False
        self._mInputState = ePureAscii
<mark>        self._mLastChar = ''</mark></code></pre>
<p>E ora abbiamo la nostra risposta. La vedete? <var>self._mLastChar</var> è una stringa, ma <var>aBuf</var> è un array di byte. E non potete concatenare una stringa a un array di byte &mdash; nemmeno una stringa di lunghezza zero.
<p>Quindi cos'è <var>self._mLastChar</var> ad ogni modo? La risposta è nel metodo <code>feed()</code>, giusto qualche riga più in basso rispetto a dove la <span class=wtf>traceback</span> è capitata.
<pre><code>if self._mInputState == ePureAscii:
    if self._highBitDetector.search(aBuf):
        self._mInputState = eHighbyte
    elif (self._mInputState == ePureAscii) and \
            self._escDetector.search(self._mLastChar + aBuf):
        self._mInputState = eEscAscii

<mark>self._mLastChar = aBuf[-1]</mark></code></pre>
<p>La funzione chiamante invoca continuamente questo metodo <code>feed()</code> con pochi byte alla volta. Il metodo elabora i byte che gli sono stati dati (passati come <var>aBuf</var>), poi memorizza l'ultimo byte in <var>self._mLastChar</var> nel caso ce ne sia bisogno durante l'invocazione successiva. (In una codifica multi-byte, il metodo <code>feed()</code> potrebbe venire invocato con metà di un carattere, e poi invocato ancora con l'altra metà.) Ma dato che <var>aBuf</var> è ora un array di byte invece che una stringa, anche <var>self._mLastChar</var> deve essere un array di byte. Perciò:
<pre><code>  def reset(self):
      .
      .
      .
<del>-     self._mLastChar = ''</del>
<ins>+     self._mLastChar = b''</ins></code></pre>
<p>Una ricerca su tutta la base di codice per &#8220;<code>mLastChar</code>&#8221; rivela un problema simile in <code>mbcharsetprober.py</code>, ma invece di tenere traccia dell'ultimo carattere, tiene traccia degli ultimi <em>due</em> caratteri. La classe <code>MultiByteCharSetProber</code> usa una lista di stringhe di 1 carattere per tenere traccia degli ultimi due caratteri; in Python 3, deve usare una lista di interi.
<pre><code>
  class MultiByteCharSetProber(CharSetProber):
      def __init__(self):
          CharSetProber.__init__(self)
          self._mDistributionAnalyzer = None
          self._mCodingSM = None
<del>-         self._mLastChar = ['\x00', '\x00']</del>
<ins>+         self._mLastChar = [0, 0]</ins>

      def reset(self):
          CharSetProber.reset(self)
          if self._mCodingSM:
              self._mCodingSM.reset()
          if self._mDistributionAnalyzer:
              self._mDistributionAnalyzer.reset()
<del>-         self._mLastChar = ['\x00', '\x00']</del>
<ins>+         self._mLastChar = [0, 0]</ins></code></pre>
<h3 id=unsupportedoperandtypeforplus>Unsupported operand type(s) for +: <code>'int'</code> and <code>'bytes'</code></h3>
<p>Ho una buona notizia e una cattiva notizia. La buona notizia è che stiamo facendo progressi&hellip;
<pre class=screen><samp class=p>C:\home\chardet> </samp><kbd>python test.py tests\*\*</kbd>
<samp>tests\ascii\howto.diveintomark.org.xml</samp>
<samp class=traceback>Traceback (most recent call last):
  File "test.py", line 10, in &lt;module>
    u.feed(line)
  File "C:\home\chardet\chardet\universaldetector.py", line 101, in feed
    self._escDetector.search(self._mLastChar + aBuf):
TypeError: unsupported operand type(s) for +: 'int' and 'bytes'</samp></pre>
<p>&hellip;La cattiva notizia è che questo non sempre sembra un progresso.
<p>Ma questo è un progresso! Davvero! Anche se la <span class=wtf>traceback</span> evidenzia la stessa riga di codice, è un errore diverso da quello di prima. Progresso! Quindi qual è ora il problema? L'ultima volta che ho controllato, questa riga di codice non provava a concatenare un <code>int</code> con un array di byte (<code>bytes</code>). Infatti, avete appena speso un sacco di tempo per <a href=#cantconvertbytesobject>assicurarvi che <var>self._mLastChar</var> fosse un vettore di byte</a>. Come si è trasformato in un <code>int</code>?
<p>La risposta non è nelle righe di codice precedenti, ma nelle righe seguenti.
<pre><code>if self._mInputState == ePureAscii:
    if self._highBitDetector.search(aBuf):
        self._mInputState = eHighbyte
    elif (self._mInputState == ePureAscii) and \
            self._escDetector.search(self._mLastChar + aBuf):
        self._mInputState = eEscAscii

<mark>self._mLastChar = aBuf[-1]</mark></code></pre>
<aside>Ogni elemento in una stringa è una stringa. Ogni elemento in un vettore di byte è un intero.</aside>
<p>Questo errore non avviene la prima volta che il metodo <code>feed()</code> viene chiamato; avviene la <em>seconda volta</em>, dopo che a <var>self._mLastChar</var> è stato assegnato l'ultimo byte di <var>aBuf</var>. E quindi, qual è il problema con quello? Recuperare un singolo elemento da un array di byte produce un intero, non un array di byte. Per vedere la differenza, seguitemi nella shell interattiva:
<pre class=screen>
<a><samp class=p>>>> </samp><kbd>aBuf = b'\xEF\xBB\xBF'</kbd>         <span>&#x2460;</span></a>
<samp class=p>>>> </samp><kbd>len(aBuf)</kbd>
<samp>3</samp>
<samp class=p>>>> </samp><kbd>mLastChar = aBuf[-1]</kbd>
<a><samp class=p>>>> </samp><kbd>mLastChar</kbd>                      <span>&#x2461;</span></a>
<samp>191</samp>
<a><samp class=p>>>> </samp><kbd>type(mLastChar)</kbd>                <span>&#x2462;</span></a>
<samp>&lt;class 'int'></samp>
<a><samp class=p>>>> </samp><kbd>mLastChar + aBuf</kbd>               <span>&#x2463;</span></a>
<samp class=traceback>Traceback (most recent call last):
  File "&lt;stdin>", line 1, in &lt;module>
TypeError: unsupported operand type(s) for +: 'int' and 'bytes'</samp>
<a><samp class=p>>>> </samp><kbd>mLastChar = aBuf[-1:]</kbd>          <span>&#x2464;</span></a>
<samp class=p>>>> </samp><kbd>mLastChar</kbd>
<samp>b'\xbf'</samp>
<a><samp class=p>>>> </samp><kbd>mLastChar + aBuf</kbd>               <span>&#x2465;</span></a>
<samp>b'\xbf\xef\xbb\xbf'</samp></pre>
<ol>
<li>Definisce un array di byte di lunghezza 3.
<li>L'ultimo elemento dell'array di byte è 191.
<li>Quello è un intero.
<li>Concatenare un intero a un array di byte non funziona. Avete ora riprodotto l'errore che avete appena trovato in <code>universaldetector.py</code>.
<li>Ah, questa è la soluzione. Invece di prendere l'ultimo elemento dell'array di byte, <a href=tipi-di-dato-nativi.html#slicinglists>affettate la lista</a> per creare un nuovo array di byte contenente solo l'ultimo elemento. Cioè, cominciate con l'ultimo elemento e continuate la fetta fino alla fine dell'array di byte. Ora <var>mLastChar</var> è un array di byte di lunghezza 1.
<li>Concatenare un array di byte di lunghezza 1 con un array di byte di lunghezza 3 restituisce un nuovo array di byte di lunghezza 4.
</ol>
<p>Quindi, per assicurarvi che il metodo <code>feed()</code> in <code>universaldetector.py</code> continui a lavorare a prescindere da quanto spesso viene invocato, dovete <a href=#cantconvertbytesobject>inizializzare <var>self._mLastChar</var> come un array di byte di lungezza 0</a>, e poi <em>assicurarvi che rimanga un array di byte</em>.
<pre><code>              self._escDetector.search(self._mLastChar + aBuf):
          self._mInputState = eEscAscii

<del>- self._mLastChar = aBuf[-1]</del>
<ins>+ self._mLastChar = aBuf[-1:]</ins></code></pre>
<h3 id=ordexpectedstring><code>ord()</code> expected string of length 1, but <code>int</code> found</h3>
<p>Già stanchi? Ci siete quasi&hellip;
<pre class=screen><samp class=p>C:\home\chardet> </samp><kbd>python test.py tests\*\*</kbd>
<samp>tests\ascii\howto.diveintomark.org.xml                       ascii with confidence 1.0
tests\Big5\0804.blogspot.com.xml</samp>
<samp class=traceback>Traceback (most recent call last):
  File "test.py", line 10, in &lt;module>
    u.feed(line)
  File "C:\home\chardet\chardet\universaldetector.py", line 116, in feed
    if prober.feed(aBuf) == constants.eFoundIt:
  File "C:\home\chardet\chardet\charsetgroupprober.py", line 60, in feed
    st = prober.feed(aBuf)
  File "C:\home\chardet\chardet\utf8prober.py", line 53, in feed
    codingState = self._mCodingSM.next_state(c)
  File "C:\home\chardet\chardet\codingstatemachine.py", line 43, in next_state
    byteCls = self._mModel['classTable'][ord(c)]
TypeError: ord() expected string of length 1, but int found</samp></pre>
<p>OK, quindi <var>c</var> è un <code>int</code>, ma la funzione <code>ord()</code> si aspetta una stringa di 1 carattere. Abbastanza onesto. Dove viene definito <var>c</var>?
<pre><code># codingstatemachine.py
def next_state(self, c):
    # for each byte we get its class
    # if it is first byte, we also get byte length
    byteCls = self._mModel['classTable'][ord(c)]</code></pre>
<p>Questo non è di aiuto; viene semplicemente passato dentro la funzione. <span class=wtf>Let's pop the stack</span>.
<pre><code># utf8prober.py
def feed(self, aBuf):
    for c in aBuf:
        codingState = self._mCodingSM.next_state(c)</code></pre>
<p>E ora abbiamo la risposta. La vedete? In Python 2, <var>aBuf</var> era una stringa, quindi <var>c</var> era una stringa di 1 carattere. (Questo è quello che si ottiene quando si itera su una stringa &mdash; tutti i caratteri, uno ad uno.) Ma ora, <var>aBuf</var> è un vettore di byte, quindi <var>c</var> è un <code>int</code>, non una stringa di 1 carattere. In altre parole, non c'è alcun bisogno di chiamare la funzione <code>ord()</code> perché <var>c</var> è già un <code>int</code>!
<p>Perciò:
<pre><code>  def next_state(self, c):
      # for each byte we get its class
      # if it is first byte, we also get byte length
<del>-     byteCls = self._mModel['classTable'][ord(c)]</del>
<ins>+     byteCls = self._mModel['classTable'][c]</ins></code></pre>
<p>Una ricerca sull'intera base di codice per istanze di &#8220;<code>ord(c)</code>&#8221; rivela problemi simili in <code>sbcharsetprober.py</code>&hellip;
<pre><code># sbcharsetprober.py
def feed(self, aBuf):
    if not self._mModel['keepEnglishLetter']:
        aBuf = self.filter_without_english_letters(aBuf)
    aLen = len(aBuf)
    if not aLen:
        return self.get_state()
    for c in aBuf:
<mark>        order = self._mModel['charToOrderMap'][ord(c)]</mark></code></pre>
<p>&hellip;e in <code>latin1prober.py</code>&hellip;
<pre><code># latin1prober.py
def feed(self, aBuf):
    aBuf = self.filter_with_english_letters(aBuf)
    for c in aBuf:
<mark>        charClass = Latin1_CharToClass[ord(c)]</mark></code></pre>
<p><var>c</var> sta iterando su <var>aBuf</var>, il che significa che è un intero, non una stringa di 1 carattere. La soluzione è la stessa: cambiare <code>ord(c)</code> al solo <code>c</code>.
<pre><code>  # sbcharsetprober.py
  def feed(self, aBuf):
      if not self._mModel['keepEnglishLetter']:
          aBuf = self.filter_without_english_letters(aBuf)
      aLen = len(aBuf)
      if not aLen:
          return self.get_state()
      for c in aBuf:
<del>-         order = self._mModel['charToOrderMap'][ord(c)]</del>
<ins>+         order = self._mModel['charToOrderMap'][c]</ins>

  # latin1prober.py
  def feed(self, aBuf):
      aBuf = self.filter_with_english_letters(aBuf)
      for c in aBuf:
<del>-         charClass = Latin1_CharToClass[ord(c)]</del>
<ins>+         charClass = Latin1_CharToClass[c]</ins>
</code></pre>
<h3 id=unorderabletypes>Unorderable types: <code>int()</code> >= <code>str()</code></h3>
<p>Continuiamo ancora.
<pre class=screen><samp class=p>C:\home\chardet> </samp><kbd>python test.py tests\*\*</kbd>
<samp>tests\ascii\howto.diveintomark.org.xml                       ascii with confidence 1.0
tests\Big5\0804.blogspot.com.xml</samp>
<samp>Traceback (most recent call last):
  File "test.py", line 10, in &lt;module>
    u.feed(line)
  File "C:\home\chardet\chardet\universaldetector.py", line 116, in feed
    if prober.feed(aBuf) == constants.eFoundIt:
  File "C:\home\chardet\chardet\charsetgroupprober.py", line 60, in feed
    st = prober.feed(aBuf)
  File "C:\home\chardet\chardet\sjisprober.py", line 68, in feed
    self._mContextAnalyzer.feed(self._mLastChar[2 - charLen :], charLen)
  File "C:\home\chardet\chardet\jpcntx.py", line 145, in feed
    order, charLen = self.get_order(aBuf[i:i+2])
  File "C:\home\chardet\chardet\jpcntx.py", line 176, in get_order
    if ((aStr[0] >= '\x81') and (aStr[0] &lt;= '\x9F')) or \
TypeError: unorderable types: int() >= str()</samp></pre>
<p>Avete notato? Questa volta, il codice ha passato il primo test (<code>tests\ascii\howto.diveintomark.org.xml</code>) con successo. State facendo progressi tangibili qui.
<p>Quindi di cosa si parla qui? &#8220;Unorderable types&#8221;? Tipi non ordinabili? Ancora una volta, la differenza tra vettori di byte e stringhe sta rialzando la sua ripugnante testa. Date un'occhiata al codice:
<pre><code>class SJISContextAnalysis(JapaneseContextAnalysis):
    def get_order(self, aStr):
        if not aStr: return -1, 1
        # find out current char's byte length
<mark>        if ((aStr[0] >= '\x81') and (aStr[0] &lt;= '\x9F')) or \</mark>
           ((aStr[0] >= '\xE0') and (aStr[0] &lt;= '\xFC')):
            charLen = 2
        else:
            charLen = 1</code></pre>
<p>E da dove viene <var>aStr</var>? <span class=wtf>Let's pop the stack</span>:
<pre><code>def feed(self, aBuf, aLen):
    .
    .
    .
    i = self._mNeedToSkipCharNum
    while i &lt; aLen:
<mark>        order, charLen = self.get_order(aBuf[i:i+2])</mark></code></pre>
<p>Oh guardate, è il nostro vecchio amico, <var>aBuf</var>. Come avrete potuto intuire da tutti gli altri problemi che abbiamo incontrato in questo capitolo, <var>aBuf</var> è un array di byte. Qui, il metodo <code>feed()</code> non sta semplicemente passandolo tutto intero; lo sta affettando. Ma come avete visto <a href=#unsupportedoperandtypeforplus>precedentemente in questo capitolo</a>, affettare un array di byte restituisce un array di byte, quindi il parametro <var>aStr</var> che viene passato al metodo <code>get_order()</code> è ancora un array di byte.
<p>E cos'è che questo codice sta cercando di fare con <var>aStr</var>? Prende il primo elemento dell'array di byte e lo confronta con una stringa di lunghezza 1. In Python 2, questo funzionava, perché <var>aStr</var> e <var>aBuf</var> erano stringhe, e <var>aStr[0]</var> sarebbe stata una stringa, e potevate confrontare le stringhe per la disuguaglianza. Ma in Python 3, <var>aStr</var> and <var>aBuf</var> sono array di byte, <var>aStr[0]</var> è un intero è non potete confrontare interi e stringhe per la disuguaglianza senza convertire esplicitamente gli uni al tipo delle altre o viceversa.
<p>In questo caso, non c'è bisogno di rendere il codice più complicato aggiungendo una conversione esplicita. <var>aStr[0]</var> produce un intero; le cose con le quali state facendo il confronto sono tutte costanti. Cambiamole da stringhe di 1 carattere a interi.
<pre><code>  class SJISContextAnalysis(JapaneseContextAnalysis):
      def get_order(self, aStr):
          if not aStr: return -1, 1
          # find out current char's byte length
<del>-         if ((aStr[0] >= '\x81') and (aStr[0] &lt;= '\x9F')) or \</del>
<del>-            ((aStr[0] >= '\xE0') and (aStr[0] &lt;= '\xFC')):</del>
<ins>+         if ((aStr[0] >= 0x81) and (aStr[0] &lt;= 0x9F)) or \</ins>
<ins>+            ((aStr[0] >= 0xE0) and (aStr[0] &lt;= 0xFC)):</ins>
              charLen = 2
          else:
              charLen = 1

          # return its order if it is hiragana
          if len(aStr) > 1:
<del>-             if (aStr[0] == '\202') and \</del>
<del>-                (aStr[1] >= '\x9F') and \</del>
<del>-                (aStr[1] &lt;= '\xF1'):</del>
<del>-                return ord(aStr[1]) - 0x9F, charLen</del>
<ins>+             if (aStr[0] == 0x202) and \</ins>
<ins>+                (aStr[1] >= 0x9F) and \</ins>
<ins>+                (aStr[1] &lt;= 0xF1):</ins>
<ins>+                return aStr[1] - 0x9F, charLen</ins>

          return -1, charLen

  class EUCJPContextAnalysis(JapaneseContextAnalysis):
      def get_order(self, aStr):
          if not aStr: return -1, 1
          # find out current char's byte length
<del>-         if (aStr[0] == '\x8E') or \</del>
<del>-           ((aStr[0] >= '\xA1') and (aStr[0] &lt;= '\xFE')):</del>
<ins>+         if (aStr[0] == 0x8E) or \</ins>
<ins>+           ((aStr[0] >= 0xA1) and (aStr[0] &lt;= 0xFE)):</ins>
              charLen = 2
<del>-         elif aStr[0] == '\x8F':</del>
<ins>+         elif aStr[0] == 0x8F:</ins>
              charLen = 3
          else:
              charLen = 1

        # return its order if it is hiragana
        if len(aStr) > 1:
<del>-           if (aStr[0] == '\xA4') and \</del>
<del>-              (aStr[1] >= '\xA1') and \</del>
<del>-              (aStr[1] &lt;= '\xF3'):</del>
<del>-                 return ord(aStr[1]) - 0xA1, charLen</del>
<ins>+           if (aStr[0] == 0xA4) and \</ins>
<ins>+              (aStr[1] >= 0xA1) and \</ins>
<ins>+              (aStr[1] &lt;= 0xF3):</ins>
<ins>+               return aStr[1] - 0xA1, charLen</ins>

        return -1, charLen</code></pre>
<p>Una ricerca sull'intera base di codice per occorrenze della funzione <code>ord()</code> rivela lo stesso problema in <code>chardistribution.py</code>:
<pre class=screen><samp class=p>C:\home\chardet> </samp><kbd>python test.py tests\*\*</kbd>
<samp>tests\ascii\howto.diveintomark.org.xml                       ascii with confidence 1.0
tests\Big5\0804.blogspot.com.xml</samp>
<samp class=traceback>Traceback (most recent call last):
  File "test.py", line 10, in &lt;module>
    u.feed(line)
  File "C:\home\chardet\chardet\universaldetector.py", line 117, in feed
    if prober.feed(aBuf) == constants.eFoundIt:
  File "C:\home\chardet\chardet\charsetgroupprober.py", line 60, in feed
    st = prober.feed(aBuf)
  File "C:\home\chardet\chardet\sjisprober.py", line 72, in feed
    self._mDistributionAnalyzer.feed(aBuf[i - 1 : i + 1], charLen)
  File "C:\home\chardet\chardet\chardistribution.py", line 56, in feed
    order = self.get_order(aStr)
  File "C:\home\chardet\chardet\chardistribution.py", line 174, in get_order
    if (aStr[0] >= '\x81') and (aStr[0] &lt;= '\x9F'):
TypeError: unorderable types: int() >= str()</samp></pre>
<p>La soluzione è la stessa:
<pre><code>  class EUCTWDistributionAnalysis(CharDistributionAnalysis):
      def __init__(self):
          CharDistributionAnalysis.__init__(self)
          self._mCharToFreqOrder = EUCTWCharToFreqOrder
          self._mTableSize = EUCTW_TABLE_SIZE
          self._mTypicalDistributionRatio = EUCTW_TYPICAL_DISTRIBUTION_RATIO

      def get_order(self, aStr):
<del>-         if aStr[0] >= '\xC4':</del>
<del>-             return 94 * (ord(aStr[0]) - 0xC4) + ord(aStr[1]) - 0xA1</del>
<ins>+         if aStr[0] >= 0xC4:</ins>
<ins>+             return 94 * (aStr[0] - 0xC4) + aStr[1] - 0xA1</ins>
          else:
              return -1

  class EUCKRDistributionAnalysis(CharDistributionAnalysis):
      def __init__(self):
          CharDistributionAnalysis.__init__(self)
          self._mCharToFreqOrder = EUCKRCharToFreqOrder
          self._mTableSize = EUCKR_TABLE_SIZE
          self._mTypicalDistributionRatio = EUCKR_TYPICAL_DISTRIBUTION_RATIO

      def get_order(self, aStr):
<del>-         if aStr[0] >= '\xB0':</del>
<del>-             return 94 * (ord(aStr[0]) - 0xB0) + ord(aStr[1]) - 0xA1</del>
<ins>+         if aStr[0] >= '\xB0':</ins>
<ins>+             return 94 * (aStr[0] - 0xB0) + aStr[1] - 0xA1</ins>
          else:
              return -1;

  class GB2312DistributionAnalysis(CharDistributionAnalysis):
      def __init__(self):
          CharDistributionAnalysis.__init__(self)
          self._mCharToFreqOrder = GB2312CharToFreqOrder
          self._mTableSize = GB2312_TABLE_SIZE
          self._mTypicalDistributionRatio = GB2312_TYPICAL_DISTRIBUTION_RATIO

      def get_order(self, aStr):
<del>-         if (aStr[0] >= '\xB0') and (aStr[1] >= '\xA1'):</del>
<del>-             return 94 * (ord(aStr[0]) - 0xB0) + ord(aStr[1]) - 0xA1</del>
<ins>+         if (aStr[0] >= 0xB0) and (aStr[1] >= 0xA1):</ins>
<ins>+             return 94 * (aStr[0] - 0xB0) + aStr[1] - 0xA1</ins>
          else:
              return -1;

  class Big5DistributionAnalysis(CharDistributionAnalysis):
      def __init__(self):
          CharDistributionAnalysis.__init__(self)
          self._mCharToFreqOrder = Big5CharToFreqOrder
          self._mTableSize = BIG5_TABLE_SIZE
          self._mTypicalDistributionRatio = BIG5_TYPICAL_DISTRIBUTION_RATIO

      def get_order(self, aStr):
<del>-         if aStr[0] >= '\xA4':</del>
<del>-             if aStr[1] >= '\xA1':</del>
<del>-                 return 157 * (ord(aStr[0]) - 0xA4) + ord(aStr[1]) - 0xA1 + 63</del>
<ins>+         if aStr[0] >= 0xA4:</ins>
<ins>+             if aStr[1] >= 0xA1:</ins>
<ins>+                 return 157 * (aStr[0] - 0xA4) + aStr[1] - 0xA1 + 63</ins>
              else:
<del>-                 return 157 * (ord(aStr[0]) - 0xA4) + ord(aStr[1]) - 0x40</del>
<ins>+                 return 157 * (aStr[0] - 0xA4) + aStr[1] - 0x40</ins>
          else:
              return -1

  class SJISDistributionAnalysis(CharDistributionAnalysis):
      def __init__(self):
          CharDistributionAnalysis.__init__(self)
          self._mCharToFreqOrder = JISCharToFreqOrder
          self._mTableSize = JIS_TABLE_SIZE
          self._mTypicalDistributionRatio = JIS_TYPICAL_DISTRIBUTION_RATIO

      def get_order(self, aStr):
<del>-         if (aStr[0] >= '\x81') and (aStr[0] &lt;= '\x9F'):</del>
<del>-             order = 188 * (ord(aStr[0]) - 0x81)</del>
<del>-         elif (aStr[0] >= '\xE0') and (aStr[0] &lt;= '\xEF'):</del>
<del>-             order = 188 * (ord(aStr[0]) - 0xE0 + 31)</del>
<ins>+         if (aStr[0] >= 0x81) and (aStr[0] &lt;= 0x9F):</ins>
<ins>+             order = 188 * (aStr[0] - 0x81)</ins>
<ins>+         elif (aStr[0] >= 0xE0) and (aStr[0] &lt;= 0xEF):</ins>
<ins>+             order = 188 * (aStr[0] - 0xE0 + 31)</ins>
          else:
              return -1;
<del>-         order = order + ord(aStr[1]) - 0x40</del>
<del>-         if aStr[1] > '\x7F':</del>
<ins>+         order = order + aStr[1] - 0x40</ins>
<ins>+         if aStr[1] > 0x7F:</ins>
              order =- 1
          return order

  class EUCJPDistributionAnalysis(CharDistributionAnalysis):
      def __init__(self):
          CharDistributionAnalysis.__init__(self)
          self._mCharToFreqOrder = JISCharToFreqOrder
          self._mTableSize = JIS_TABLE_SIZE
          self._mTypicalDistributionRatio = JIS_TYPICAL_DISTRIBUTION_RATIO

      def get_order(self, aStr):
<del>-         if aStr[0] >= '\xA0':</del>
<del>-             return 94 * (ord(aStr[0]) - 0xA1) + ord(aStr[1]) - 0xA1</del>
<ins>+         if aStr[0] >= 0xA0:</ins>
<ins>+             return 94 * (aStr[0] - 0xA1) + aStr[1] - 0xA1</ins>
          else:
              return -1</code></pre>
<h3 id=reduceisnotdefined>Global name <code>'reduce'</code> is not defined</h3>
<p>Ancora una volta nella breccia&hellip;
<pre class=screen><samp class=p>C:\home\chardet> </samp><kbd>python test.py tests\*\*</kbd>
<samp>tests\ascii\howto.diveintomark.org.xml                       ascii with confidence 1.0
tests\Big5\0804.blogspot.com.xml</samp>
<samp class=traceback>Traceback (most recent call last):
  File "test.py", line 12, in &lt;module>
    u.close()
  File "C:\home\chardet\chardet\universaldetector.py", line 141, in close
    proberConfidence = prober.get_confidence()
  File "C:\home\chardet\chardet\latin1prober.py", line 126, in get_confidence
    total = reduce(operator.add, self._mFreqCounter)
NameError: global name 'reduce' is not defined</samp></pre>
<p>Secondo la guida ufficiale alle novità di Python 3, <a href=http://docs.python.org/3.0/whatsnew/3.0.html#builtins>What's New In Python 3.0</a>, la funzione <code>reduce()</code> è stata spostata dallo spazio di nomi globale nel modulo <code>functools</code>. Per citare la guida: &#8220;Usate <code>functools.reduce()</code> se proprio ne avete bisogno; comunque, il 99 per cento delle volte un esplicito ciclo <code>for</code> è più leggibile.&#8221; Potete approfondire le motivazioni di questa decisione sul blog di Guido van Rossum: <a href="http://www.artima.com/weblogs/viewpost.jsp?thread=98196">The fate of reduce() in Python 3000</a>. (Il destino di <code>reduce()</code> in Python 3000.)
<pre><code>def get_confidence(self):
    if self.get_state() == constants.eNotMe:
        return 0.01
  
<mark>    total = reduce(operator.add, self._mFreqCounter)</mark></code></pre>
<p>La funzione <code>reduce()</code> prende due argomenti &mdash; una funzione e una lista (strettamente parlando, qualsiasi oggetto iterabile potrebbe andare) &mdash; e applica una funzione cumulativamente a ogni elemento nella lista. In altre parole, questo è un modo elaborato e tortuoso di sommare tutti gli elementi in una lista e restituire il risultato.
<p>Questa mostruosità era così comune che Python ha aggiunto una funzione globale <code>sum()</code>.
<pre><code>  def get_confidence(self):
      if self.get_state() == constants.eNotMe:
          return 0.01
  
<del>-     total = reduce(operator.add, self._mFreqCounter)</del>
<ins>+     total = sum(self._mFreqCounter)</ins></code></pre>
<p>Dato che non state più usando il modulo <code>operator</code>, potete anche rimuovere quella istruzione di <code>import</code> dall'inizio del file.
<pre><code>  from .charsetprober import CharSetProber
  from . import constants
<del>- import operator</del></code></pre>
<p>I CAN HAZ TESTZ?
<pre class=screen><samp class=p>C:\home\chardet> </samp><kbd>python test.py tests\*\*</kbd>
<samp>tests\ascii\howto.diveintomark.org.xml                       ascii with confidence 1.0
tests\Big5\0804.blogspot.com.xml                             Big5 with confidence 0.99
tests\Big5\blog.worren.net.xml                               Big5 with confidence 0.99
tests\Big5\carbonxiv.blogspot.com.xml                        Big5 with confidence 0.99
tests\Big5\catshadow.blogspot.com.xml                        Big5 with confidence 0.99
tests\Big5\coolloud.org.tw.xml                               Big5 with confidence 0.99
tests\Big5\digitalwall.com.xml                               Big5 with confidence 0.99
tests\Big5\ebao.us.xml                                       Big5 with confidence 0.99
tests\Big5\fudesign.blogspot.com.xml                         Big5 with confidence 0.99
tests\Big5\kafkatseng.blogspot.com.xml                       Big5 with confidence 0.99
tests\Big5\ke207.blogspot.com.xml                            Big5 with confidence 0.99
tests\Big5\leavesth.blogspot.com.xml                         Big5 with confidence 0.99
tests\Big5\letterlego.blogspot.com.xml                       Big5 with confidence 0.99
tests\Big5\linyijen.blogspot.com.xml                         Big5 with confidence 0.99
tests\Big5\marilynwu.blogspot.com.xml                        Big5 with confidence 0.99
tests\Big5\myblog.pchome.com.tw.xml                          Big5 with confidence 0.99
tests\Big5\oui-design.com.xml                                Big5 with confidence 0.99
tests\Big5\sanwenji.blogspot.com.xml                         Big5 with confidence 0.99
tests\Big5\sinica.edu.tw.xml                                 Big5 with confidence 0.99
tests\Big5\sylvia1976.blogspot.com.xml                       Big5 with confidence 0.99
tests\Big5\tlkkuo.blogspot.com.xml                           Big5 with confidence 0.99
tests\Big5\tw.blog.xubg.com.xml                              Big5 with confidence 0.99
tests\Big5\unoriginalblog.com.xml                            Big5 with confidence 0.99
tests\Big5\upsaid.com.xml                                    Big5 with confidence 0.99
tests\Big5\willythecop.blogspot.com.xml                      Big5 with confidence 0.99
tests\Big5\ytc.blogspot.com.xml                              Big5 with confidence 0.99
tests\EUC-JP\aivy.co.jp.xml                                  EUC-JP with confidence 0.99
tests\EUC-JP\akaname.main.jp.xml                             EUC-JP with confidence 0.99
tests\EUC-JP\arclamp.jp.xml                                  EUC-JP with confidence 0.99
.
.
.
316 tests</samp></pre>
<p>Porca puttana, funziona davvero! <em><a href=http://www.hampsterdance.com/>/me fa una piccola danza</a></em>
<h2 id=summary>Riepilogo</h2>
<p>Che cosa abbiamo imparato?
<ol>
<li>Convertire qualsiasi quantità non banale di codice da Python 2 verso Python 3 sarà doloroso. Non c'è alcun modo di evitarlo. &Egrave; difficile.
<li>Lo <a href=porting-code-to-python-3-with-2to3.html>stumento automatico <code>2to3</code></a> è utile per quello che può fare, ma farà solo la parte facile &mdash; rinominerà le funzioni e i moduli, modificherà la sintassi. &Egrave; un impressionante esempio di ingegneria, ma alla fine è solo un automa intelligente per la ricerca e la sostituzione.
<li>Il problema n°1 nella conversione di questa libreria era la differenza tra stringhe e byte. In questo caso sembrava ovvio, dato che lo scopo stesso della libreria <code>chardet</code> è convertire un flusso di byte in una stringa. Ma &#8220;un flusso di byte&#8221; viene fuori molto più spesso di quanto possiate immaginare. Leggete un file in modalità &#8220;binaria&#8221;? Avrete un flusso di byte. Recuperate una pagina web? Chiamate una <abbr>API</abbr> web? Anche quelle restituiscono un flusso di byte.
<li><em>Voi</em> avete bisogno di capire il vostro programma. Completamente. Preferibilmente perché lo avete scritto, ma avete almeno bisogno di trovarvi a vostro agio con tutte le sue stranezze e i suoi angoli ammuffiti. I bug si annidano dovunque.
<li>I test sono essenziali. Non convertite nulla senza di loro. Non provateci nemmeno. L'<em>unica</em> ragione per cui ho una qualche confidenza che <code>chardet</code> funzioni in Python 3 è perché avevo una <span class=wtf>test suite</span> che esercitava ogni riga di codice nell'intera libreria. Non sarei <em>mai</em> riuscito a trovare la metà di questi problemi facendo una ricerca manuale.
</ol>
<p class=nav><a rel=prev class=todo><span>&#x261C;</span></a> <a rel=next href=convertire-codice-verso-python-3-con-2to3.html title="avanti a &#8220;Convertire codice verso Python 3 con 2to3&#8221;"><span>&#x261E;</span></a>
<p class=c>&copy; 2001&ndash;9 <a href=informazioni-sul-libro.html>Mark Pilgrim</a><br>
&copy; 2009 <a href=informazioni-sulla-traduzione.html>Giulio Piancastelli</a> per la traduzione italiana
<script src=jquery.js></script>
<script src=dip3.js></script>
